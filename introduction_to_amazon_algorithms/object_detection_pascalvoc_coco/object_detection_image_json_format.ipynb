{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confidential-scope",
   "metadata": {
    "papermill": {
     "duration": 0.023539,
     "end_time": "2021-06-14T00:12:25.316913",
     "exception": false,
     "start_time": "2021-06-14T00:12:25.293374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Amazon SageMaker Object Detection using the Image and JSON format\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Data Preparation](#Data-Preparation)\n",
    "  1. [Download data](#Download-Data)\n",
    "  2. [Prepare Dataset](#Prepare-dataset)\n",
    "  3. [Upload to S3](#Upload-to-S3)\n",
    "4. [Training](#Training)\n",
    "5. [Hosting](#Hosting)\n",
    "6. [Inference](#Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-german",
   "metadata": {
    "papermill": {
     "duration": 0.022774,
     "end_time": "2021-06-14T00:12:25.362788",
     "exception": false,
     "start_time": "2021-06-14T00:12:25.340014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Object detection is the process of identifying and localizing objects in an image. A typical object detection solution takes in an image as input and provides a bounding box on the image where an object of interest is, along with identifying what object the box encapsulates. But before we have this solution, we need to acquire and process a traning dataset, create and setup a training job for the alorithm so that the aglorithm can learn about the dataset and then host the algorithm as an endpoint, to which we can supply the query image.\n",
    "\n",
    "This notebook is an end-to-end example introducing the Amazon SageMaker Object Detection algorithm. In this demo, we will demonstrate how to train and to host an object detection model on the [COCO dataset](http://cocodataset.org/) using the Single Shot multibox Detector ([SSD](https://arxiv.org/abs/1512.02325)) algorithm. In doing so, we will also demonstrate how to construct a training dataset using the JSON format as this is the format that the training job will consume. We also allow the RecordIO format, which is illustrated in the [RecordIO Notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_recordio_format.ipynb). We will also demonstrate how to host and validate this trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-death",
   "metadata": {
    "papermill": {
     "duration": 0.022712,
     "end_time": "2021-06-14T00:12:25.408274",
     "exception": false,
     "start_time": "2021-06-14T00:12:25.385562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "To train the Object Detection algorithm on Amazon SageMaker, we need to setup and authenticate the use of AWS services. To begin with we need an AWS account role with SageMaker access. This role is used to give SageMaker access to your data in S3 will automatically be obtained from the role used to start the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stylish-asset",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T00:12:25.462800Z",
     "iopub.status.busy": "2021-06-14T00:12:25.462175Z",
     "iopub.status.idle": "2021-06-14T00:12:27.012560Z",
     "shell.execute_reply": "2021-06-14T00:12:27.013022Z"
    },
    "papermill": {
     "duration": 1.582216,
     "end_time": "2021-06-14T00:12:27.013273",
     "exception": false,
     "start_time": "2021-06-14T00:12:25.431057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::521695447989:role/ProdBuildSystemStack-ReleaseBuildRoleFB326D49-QK8LUA2UI1IC\n",
      "CPU times: user 1.22 s, sys: 290 ms, total: 1.51 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-recording",
   "metadata": {
    "papermill": {
     "duration": 0.023268,
     "end_time": "2021-06-14T00:12:27.061441",
     "exception": false,
     "start_time": "2021-06-14T00:12:27.038173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also need the S3 bucket that you want to use for training and to store the tranied model artifacts. In this notebook, we require a custom bucket that exists so as to keep the naming clean. You can end up using a default bucket that SageMaker comes with as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serious-subscriber",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:12:27.151800Z",
     "iopub.status.busy": "2021-06-14T00:12:27.150776Z",
     "iopub.status.idle": "2021-06-14T00:12:27.942649Z",
     "shell.execute_reply": "2021-06-14T00:12:27.942049Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.819155,
     "end_time": "2021-06-14T00:12:27.942780",
     "exception": false,
     "start_time": "2021-06-14T00:12:27.123625",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "bucket = sess.default_bucket()\n",
    "prefix = \"DEMO-ObjectDetection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-school",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T00:12:27.993381Z",
     "iopub.status.busy": "2021-06-14T00:12:27.992813Z",
     "iopub.status.idle": "2021-06-14T00:12:27.995022Z",
     "shell.execute_reply": "2021-06-14T00:12:27.995464Z"
    },
    "papermill": {
     "duration": 0.029283,
     "end_time": "2021-06-14T00:12:27.995608",
     "exception": false,
     "start_time": "2021-06-14T00:12:27.966325",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "kms_key = \"arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conscious-italy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T00:12:28.047167Z",
     "iopub.status.busy": "2021-06-14T00:12:28.046392Z",
     "iopub.status.idle": "2021-06-14T00:12:28.059920Z",
     "shell.execute_reply": "2021-06-14T00:12:28.060362Z"
    },
    "papermill": {
     "duration": 0.041402,
     "end_time": "2021-06-14T00:12:28.060516",
     "exception": false,
     "start_time": "2021-06-14T00:12:28.019114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433757028032.dkr.ecr.us-west-2.amazonaws.com/object-detection:1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, \"object-detection\", repo_version=\"latest\")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-rugby",
   "metadata": {
    "papermill": {
     "duration": 0.024465,
     "end_time": "2021-06-14T00:12:28.110054",
     "exception": false,
     "start_time": "2021-06-14T00:12:28.085589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation\n",
    "[MS COCO](http://cocodataset.org/#download) is a large-scale dataset for multiple computer vision tasks, including object detection, segmentation, and captioning. In this notebook, we will use the object detection dataset. Since the COCO is relative large dataset, we will only use the the validation set from 2017 and split them into training and validation sets. The data set from 2017 contains 5000 images with objects from 80 categories.\n",
    "\n",
    "### Datset License\n",
    "The annotations in this dataset belong to the COCO Consortium and are licensed under a Creative Commons Attribution 4.0 License. The COCO Consortium does not own the copyright of the images. Use of the images must abide by the Flickr Terms of Use. The users of the images accept full responsibility for the use of the dataset, including but not limited to the use of any copies of copyrighted images that they may create from the dataset. Before you use this data for any other purpose than this example, you should understand the data license, described at http://cocodataset.org/#termsofuse\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-playback",
   "metadata": {
    "papermill": {
     "duration": 0.024195,
     "end_time": "2021-06-14T00:12:28.158672",
     "exception": false,
     "start_time": "2021-06-14T00:12:28.134477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Download data\n",
    "Let us download the 2017 validation datasets from COCO and then unpack them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conservative-destiny",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:12:28.213776Z",
     "iopub.status.busy": "2021-06-14T00:12:28.213213Z",
     "iopub.status.idle": "2021-06-14T00:13:15.797155Z",
     "shell.execute_reply": "2021-06-14T00:13:15.797633Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 47.614784,
     "end_time": "2021-06-14T00:13:15.797788",
     "exception": false,
     "start_time": "2021-06-14T00:12:28.183004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "# MSCOCO validation image files\n",
    "download(\"http://images.cocodataset.org/zips/val2017.zip\")\n",
    "download(\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electoral-retirement",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:13:15.850816Z",
     "iopub.status.busy": "2021-06-14T00:13:15.850238Z",
     "iopub.status.idle": "2021-06-14T00:13:34.184661Z",
     "shell.execute_reply": "2021-06-14T00:13:34.184142Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 18.362278,
     "end_time": "2021-06-14T00:13:34.184786",
     "exception": false,
     "start_time": "2021-06-14T00:13:15.822508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "unzip -qo val2017.zip\n",
    "unzip -qo annotations_trainval2017.zip\n",
    "rm val2017.zip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-officer",
   "metadata": {
    "papermill": {
     "duration": 0.025558,
     "end_time": "2021-06-14T00:13:34.237400",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.211842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before using this dataset, we need to perform some data cleaning. The algorithm expects the dataset in a particular JSON format. The COCO dataset, while containing annotations in JSON, does not follow our specifications. We will use this as an opportunity to introduce our JSON format by performing this convertion. To begin with we create appropriate directories for training images, validation images, as well as the annotation files for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polish-psychology",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:13:34.293715Z",
     "iopub.status.busy": "2021-06-14T00:13:34.290670Z",
     "iopub.status.idle": "2021-06-14T00:13:34.303447Z",
     "shell.execute_reply": "2021-06-14T00:13:34.302986Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.041608,
     "end_time": "2021-06-14T00:13:34.303578",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.261970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Create folders to store the data and annotation files\n",
    "mkdir generated train train_annotation validation validation_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-condition",
   "metadata": {
    "papermill": {
     "duration": 0.024679,
     "end_time": "2021-06-14T00:13:34.353446",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.328767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare dataset \n",
    "\n",
    "Next, we should convert the annotation file from the COCO dataset into json annotation files. We will require one annotation for each image.\n",
    "\n",
    "The Amazon SageMaker Object Detection algorithm expects lables to be indexed from `0`. It also expects lables to be unique, successive and not skip any integers. For instance, if there are ten classes, the algorithm expects and the labels only be in the set `[0,1,2,3,4,5,6,7,8,9]`. \n",
    "\n",
    "In the COCO validation set unfortunately, the labels do not satistify this requirement. Some indices are skipped and the labels start from `1`. We therefore need a mapper that will convert this index system to our requirement. Let us create a generic mapper therefore that could also be used to other datasets that might have nonunique or even string labels. All we need in a dictionary that would create a key-value mapping where an original label is hashed to a label that we require. Consider the following method that returns such a dictionary for the COCO validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superb-amendment",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:13:34.411899Z",
     "iopub.status.busy": "2021-06-14T00:13:34.411052Z",
     "iopub.status.idle": "2021-06-14T00:13:34.413629Z",
     "shell.execute_reply": "2021-06-14T00:13:34.413164Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.03551,
     "end_time": "2021-06-14T00:13:34.413748",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.378238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "\n",
    "def get_coco_mapper():\n",
    "    original_list = [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        11,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        24,\n",
    "        25,\n",
    "        27,\n",
    "        28,\n",
    "        31,\n",
    "        32,\n",
    "        33,\n",
    "        34,\n",
    "        35,\n",
    "        36,\n",
    "        37,\n",
    "        38,\n",
    "        39,\n",
    "        40,\n",
    "        41,\n",
    "        42,\n",
    "        43,\n",
    "        44,\n",
    "        46,\n",
    "        47,\n",
    "        48,\n",
    "        49,\n",
    "        50,\n",
    "        51,\n",
    "        52,\n",
    "        53,\n",
    "        54,\n",
    "        55,\n",
    "        56,\n",
    "        57,\n",
    "        58,\n",
    "        59,\n",
    "        60,\n",
    "        61,\n",
    "        62,\n",
    "        63,\n",
    "        64,\n",
    "        65,\n",
    "        67,\n",
    "        70,\n",
    "        72,\n",
    "        73,\n",
    "        74,\n",
    "        75,\n",
    "        76,\n",
    "        77,\n",
    "        78,\n",
    "        79,\n",
    "        80,\n",
    "        81,\n",
    "        82,\n",
    "        84,\n",
    "        85,\n",
    "        86,\n",
    "        87,\n",
    "        88,\n",
    "        89,\n",
    "        90,\n",
    "    ]\n",
    "    iter_counter = 0\n",
    "    COCO = {}\n",
    "    for orig in original_list:\n",
    "        COCO[orig] = iter_counter\n",
    "        iter_counter += 1\n",
    "    return COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-puppy",
   "metadata": {
    "papermill": {
     "duration": 0.024756,
     "end_time": "2021-06-14T00:13:34.463467",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.438711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us use this dictionary, to create a look up method. Let us do so in a way that any dictionary could be used to create this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "permanent-scope",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:13:34.517878Z",
     "iopub.status.busy": "2021-06-14T00:13:34.517049Z",
     "iopub.status.idle": "2021-06-14T00:13:34.519617Z",
     "shell.execute_reply": "2021-06-14T00:13:34.519062Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.031487,
     "end_time": "2021-06-14T00:13:34.519735",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.488248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mapper_fn(map):\n",
    "    def mapper(in_category):\n",
    "        return map[in_category]\n",
    "\n",
    "    return mapper\n",
    "\n",
    "\n",
    "fix_index_mapping = get_mapper_fn(get_coco_mapper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-paintball",
   "metadata": {
    "papermill": {
     "duration": 0.025377,
     "end_time": "2021-06-14T00:13:34.570088",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.544711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The method `fix_index_mapping` is essentially a look-up method, which we can use to convert lables. Let us now iterate over every annotation in the COCO dataset and prepare our data. Note how the keywords are created and a structure is established. For more information on the JSON format details, refer the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optimum-making",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:13:34.629816Z",
     "iopub.status.busy": "2021-06-14T00:13:34.629210Z",
     "iopub.status.idle": "2021-06-14T00:14:34.049921Z",
     "shell.execute_reply": "2021-06-14T00:14:34.050377Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 59.45543,
     "end_time": "2021-06-14T00:14:34.050544",
     "exception": false,
     "start_time": "2021-06-14T00:13:34.595114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"./annotations/instances_val2017.json\"\n",
    "with open(file_name) as f:\n",
    "    js = json.load(f)\n",
    "    images = js[\"images\"]\n",
    "    categories = js[\"categories\"]\n",
    "    annotations = js[\"annotations\"]\n",
    "    for i in images:\n",
    "        jsonFile = i[\"file_name\"]\n",
    "        jsonFile = jsonFile.split(\".\")[0] + \".json\"\n",
    "\n",
    "        line = {}\n",
    "        line[\"file\"] = i[\"file_name\"]\n",
    "        line[\"image_size\"] = [{\"width\": int(i[\"width\"]), \"height\": int(i[\"height\"]), \"depth\": 3}]\n",
    "        line[\"annotations\"] = []\n",
    "        line[\"categories\"] = []\n",
    "        for j in annotations:\n",
    "            if j[\"image_id\"] == i[\"id\"] and len(j[\"bbox\"]) > 0:\n",
    "                line[\"annotations\"].append(\n",
    "                    {\n",
    "                        \"class_id\": int(fix_index_mapping(j[\"category_id\"])),\n",
    "                        \"top\": int(j[\"bbox\"][1]),\n",
    "                        \"left\": int(j[\"bbox\"][0]),\n",
    "                        \"width\": int(j[\"bbox\"][2]),\n",
    "                        \"height\": int(j[\"bbox\"][3]),\n",
    "                    }\n",
    "                )\n",
    "                class_name = \"\"\n",
    "                for k in categories:\n",
    "                    if int(j[\"category_id\"]) == k[\"id\"]:\n",
    "                        class_name = str(k[\"name\"])\n",
    "                assert class_name is not \"\"\n",
    "                line[\"categories\"].append({\"class_id\": int(j[\"category_id\"]), \"name\": class_name})\n",
    "        if line[\"annotations\"]:\n",
    "            with open(os.path.join(\"generated\", jsonFile), \"w\") as p:\n",
    "                json.dump(line, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gothic-royalty",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:14:34.104629Z",
     "iopub.status.busy": "2021-06-14T00:14:34.104073Z",
     "iopub.status.idle": "2021-06-14T00:14:34.110455Z",
     "shell.execute_reply": "2021-06-14T00:14:34.109892Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.034866,
     "end_time": "2021-06-14T00:14:34.110577",
     "exception": false,
     "start_time": "2021-06-14T00:14:34.075711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4952 images have annotation files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "jsons = os.listdir(\"generated\")\n",
    "\n",
    "print(\"There are {} images have annotation files\".format(len(jsons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-london",
   "metadata": {
    "papermill": {
     "duration": 0.025235,
     "end_time": "2021-06-14T00:14:34.161170",
     "exception": false,
     "start_time": "2021-06-14T00:14:34.135935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After removing the images without annotations, we have 4952 annotated images. Let us split this dataset and create our training and validation datasets, with which our algorithm will train. To do so, we will simply split the dataset into training and validation data and move them to their respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focal-playing",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:14:34.217510Z",
     "iopub.status.busy": "2021-06-14T00:14:34.216910Z",
     "iopub.status.idle": "2021-06-14T00:14:34.503610Z",
     "shell.execute_reply": "2021-06-14T00:14:34.503013Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.31736,
     "end_time": "2021-06-14T00:14:34.503732",
     "exception": false,
     "start_time": "2021-06-14T00:14:34.186372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "train_jsons = jsons[:4452]\n",
    "val_jsons = jsons[4452:]\n",
    "\n",
    "# Moving training files to the training folders\n",
    "for i in train_jsons:\n",
    "    image_file = \"./val2017/\" + i.split(\".\")[0] + \".jpg\"\n",
    "    shutil.move(image_file, \"./train/\")\n",
    "    shutil.move(\"./generated/\" + i, \"./train_annotation/\")\n",
    "\n",
    "# Moving validation files to the validation folders\n",
    "for i in val_jsons:\n",
    "    image_file = \"./val2017/\" + i.split(\".\")[0] + \".jpg\"\n",
    "    shutil.move(image_file, \"./validation/\")\n",
    "    shutil.move(\"./generated/\" + i, \"./validation_annotation/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-video",
   "metadata": {
    "papermill": {
     "duration": 0.026992,
     "end_time": "2021-06-14T00:14:34.556336",
     "exception": false,
     "start_time": "2021-06-14T00:14:34.529344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Upload to S3\n",
    "Next step in this process is to upload the data to the S3 bucket, from which the algorithm can read and use the data. We do this using multiple channels. Channels are simply directories in the bucket that differentiate between training and validation data. Let us simply call these directories `train` and `validation`. We will therefore require four channels: two for the data and two for annotations, the annotations ones named with the suffixes `_annotation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broken-pacific",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:14:34.613033Z",
     "iopub.status.busy": "2021-06-14T00:14:34.612109Z",
     "iopub.status.idle": "2021-06-14T00:25:11.048451Z",
     "shell.execute_reply": "2021-06-14T00:25:11.048912Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 636.467236,
     "end_time": "2021-06-14T00:25:11.049081",
     "exception": false,
     "start_time": "2021-06-14T00:14:34.581845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.6 s, sys: 5.03 s, total: 1min 2s\n",
      "Wall time: 10min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + \"/train\"\n",
    "validation_channel = prefix + \"/validation\"\n",
    "train_annotation_channel = prefix + \"/train_annotation\"\n",
    "validation_annotation_channel = prefix + \"/validation_annotation\"\n",
    "\n",
    "sess.upload_data(path=\"train\", bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path=\"validation\", bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path=\"train_annotation\", bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(\n",
    "    path=\"validation_annotation\", bucket=bucket, key_prefix=validation_annotation_channel\n",
    ")\n",
    "\n",
    "s3_train_data = \"s3://{}/{}\".format(bucket, train_channel)\n",
    "s3_validation_data = \"s3://{}/{}\".format(bucket, validation_channel)\n",
    "s3_train_annotation = \"s3://{}/{}\".format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = \"s3://{}/{}\".format(bucket, validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-asbestos",
   "metadata": {
    "papermill": {
     "duration": 0.025727,
     "end_time": "2021-06-14T00:25:11.100665",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.074938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we need to setup an output location at S3, where the model artifact will be dumped. These artifacts are also the output of the algorithm's traning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "satisfactory-cylinder",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:25:11.156739Z",
     "iopub.status.busy": "2021-06-14T00:25:11.155969Z",
     "iopub.status.idle": "2021-06-14T00:25:11.158065Z",
     "shell.execute_reply": "2021-06-14T00:25:11.158551Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.031974,
     "end_time": "2021-06-14T00:25:11.158696",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.126722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-flood",
   "metadata": {
    "papermill": {
     "duration": 0.025768,
     "end_time": "2021-06-14T00:25:11.210314",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.184546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "Now that we are done with all the setup that is needed, we are ready to train our object detector. To begin, let us create a ``sageMaker.estimator.Estimator`` object. This estimator will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exempt-pride",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:25:11.266912Z",
     "iopub.status.busy": "2021-06-14T00:25:11.266129Z",
     "iopub.status.idle": "2021-06-14T00:25:11.271452Z",
     "shell.execute_reply": "2021-06-14T00:25:11.271001Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.035374,
     "end_time": "2021-06-14T00:25:11.271604",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.236230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "od_model = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.p3.2xlarge\",\n",
    "    train_volume_size=50,\n",
    "    train_max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-climb",
   "metadata": {
    "papermill": {
     "duration": 0.027117,
     "end_time": "2021-06-14T00:25:11.326264",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.299147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The object detection algorithm at its core is the [Single-Shot Multi-Box detection algorithm (SSD)](https://arxiv.org/abs/1512.02325). This algorithm uses a `base_network`, which is typically a [VGG](https://arxiv.org/abs/1409.1556) or a [ResNet](https://arxiv.org/abs/1512.03385). The Amazon SageMaker object detection algorithm supports VGG-16 and ResNet-50 now. It also has a lot of options for hyperparameters that help configure the training job. The next step in our training, is to setup these hyperparameters and data channels for training the model. Consider the following example definition of hyperparameters. See the SageMaker Object Detection [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html) for more details on the hyperparameters.\n",
    "\n",
    "One of the hyperparameters here for instance is the `epochs`. This defines how many passes of the dataset we iterate over and determines that training time of the algorithm. For the sake of demonstration let us run only `30` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rational-desire",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:25:11.386080Z",
     "iopub.status.busy": "2021-06-14T00:25:11.385227Z",
     "iopub.status.idle": "2021-06-14T00:25:11.387915Z",
     "shell.execute_reply": "2021-06-14T00:25:11.387446Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.034542,
     "end_time": "2021-06-14T00:25:11.388032",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.353490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "od_model.set_hyperparameters(\n",
    "    base_network=\"resnet-50\",\n",
    "    use_pretrained_model=1,\n",
    "    num_classes=80,\n",
    "    mini_batch_size=16,\n",
    "    epochs=30,\n",
    "    learning_rate=0.001,\n",
    "    lr_scheduler_step=\"10\",\n",
    "    lr_scheduler_factor=0.1,\n",
    "    optimizer=\"sgd\",\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    overlap_threshold=0.5,\n",
    "    nms_threshold=0.45,\n",
    "    image_shape=512,\n",
    "    label_width=600,\n",
    "    num_training_samples=4452,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-speaker",
   "metadata": {
    "papermill": {
     "duration": 0.02719,
     "end_time": "2021-06-14T00:25:11.442557",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.415367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that the hyperparameters are setup, let us prepare the handshake between our data channels and the algorithm. To do this, we need to create the `sagemaker.session.s3_input` objects from our data channels. These objects are then put in a simple dictionary, which the algorithm consumes. Notice that here we use a `content_type` as `image/jpeg` for the image channels and the annoation channels. Notice how unlike the [RecordIO format](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_recordio_format.ipynb), we use four channels here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tutorial-confidentiality",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:25:11.503195Z",
     "iopub.status.busy": "2021-06-14T00:25:11.502276Z",
     "iopub.status.idle": "2021-06-14T00:25:11.508583Z",
     "shell.execute_reply": "2021-06-14T00:25:11.508049Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.039048,
     "end_time": "2021-06-14T00:25:11.508698",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.469650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "train_data = sagemaker.session.s3_input(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"image/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.session.s3_input(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"image/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "train_annotation = sagemaker.session.s3_input(\n",
    "    s3_train_annotation,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"image/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_annotation = sagemaker.session.s3_input(\n",
    "    s3_validation_annotation,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"image/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": train_data,\n",
    "    \"validation\": validation_data,\n",
    "    \"train_annotation\": train_annotation,\n",
    "    \"validation_annotation\": validation_annotation,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-supplier",
   "metadata": {
    "papermill": {
     "duration": 0.02827,
     "end_time": "2021-06-14T00:25:11.565322",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.537052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have our `Estimator` object, we have set the hyperparameters for this object and we have our data channels linked with the algorithm. The only remaining thing to do is to train the algorithm. The following cell will train the algorithm. Training the algorithm involves a few steps. Firstly, the instances that we requested while creating the `Estimator` classes are provisioned and are setup with the appropriate libraries. Then, the data from our channels are downloaded into the instance. Once this is done, the training job begins. The provisioning and data downloading will take time, depending on the size of the data. Therefore it might be a few minutes before we start getting data logs for our training jobs. The data logs will also print out Mean Average Precision (mAP) on the validation data, among other losses, for every run of the dataset once or one epoch. This metric is a proxy for the quality of the algorithm. \n",
    "\n",
    "Once the job has finished a \"Job complete\" message will be printed. The trained model can be found in the S3 bucket that was setup as `output_path` in the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "virtual-wagon",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T00:25:11.626496Z",
     "iopub.status.busy": "2021-06-14T00:25:11.625892Z",
     "iopub.status.idle": "2021-06-14T01:41:11.625530Z",
     "shell.execute_reply": "2021-06-14T01:41:11.625963Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 4560.032506,
     "end_time": "2021-06-14T01:41:11.626114",
     "exception": false,
     "start_time": "2021-06-14T00:25:11.593608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-14 00:25:11 Starting - Starting the training job...\n",
      "2021-06-14 00:25:40 Starting - Launching requested ML instancesProfilerReport-1623630311: InProgress\n",
      "......\n",
      "2021-06-14 00:26:40 Starting - Preparing the instances for training.........\n",
      "2021-06-14 00:28:01 Downloading - Downloading input data...............\n",
      "2021-06-14 00:30:41 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'base_network': 'vgg-16', 'use_pretrained_model': '0', 'num_classes': '', 'mini_batch_size': '32', 'epochs': '30', 'learning_rate': '0.001', 'lr_scheduler_step': '', 'lr_scheduler_factor': '0.1', 'optimizer': 'sgd', 'momentum': '0.9', 'weight_decay': '0.0005', 'overlap_threshold': '0.5', 'nms_threshold': '0.45', 'num_training_samples': '', 'image_shape': '300', '_tuning_objective_metric': '', '_kvstore': 'device', 'kv_store': 'device', '_num_kv_servers': 'auto', 'label_width': '350', 'freeze_layer_pattern': '', 'nms_topk': '400', 'early_stopping': 'False', 'early_stopping_min_epochs': '10', 'early_stopping_patience': '5', 'early_stopping_tolerance': '0.0', '_begin_epoch': '0'}\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'weight_decay': '0.0005', 'num_classes': '80', 'num_training_samples': '4452', 'lr_scheduler_step': '10', 'overlap_threshold': '0.5', 'image_shape': '512', 'label_width': '600', 'momentum': '0.9', 'nms_threshold': '0.45', 'lr_scheduler_factor': '0.1', 'optimizer': 'sgd', 'base_network': 'resnet-50', 'use_pretrained_model': '1', 'epochs': '30', 'learning_rate': '0.001', 'mini_batch_size': '16'}\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Final configuration: {'base_network': 'resnet-50', 'use_pretrained_model': '1', 'num_classes': '80', 'mini_batch_size': '16', 'epochs': '30', 'learning_rate': '0.001', 'lr_scheduler_step': '10', 'lr_scheduler_factor': '0.1', 'optimizer': 'sgd', 'momentum': '0.9', 'weight_decay': '0.0005', 'overlap_threshold': '0.5', 'nms_threshold': '0.45', 'num_training_samples': '4452', 'image_shape': '512', '_tuning_objective_metric': '', '_kvstore': 'device', 'kv_store': 'device', '_num_kv_servers': 'auto', 'label_width': '600', 'freeze_layer_pattern': '', 'nms_topk': '400', 'early_stopping': 'False', 'early_stopping_min_epochs': '10', 'early_stopping_patience': '5', 'early_stopping_tolerance': '0.0', '_begin_epoch': '0'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:56 INFO 140696405849920] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\n",
      "2021-06-14 00:31:01 Training - Training image download completed. Training in progress.\u001b[34m[06/14/2021 00:30:59 INFO 140696405849920] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:30:59 INFO 140696405849920] nvidia-smi identified 1 GPUs.\u001b[0m\n",
      "\u001b[34mCreating .rec file from /opt/ml/input/data/train/train.lst in /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mtime: 0.1307218074798584  count: 0\u001b[0m\n",
      "\u001b[34mtime: 1.8905408382415771  count: 1000\u001b[0m\n",
      "\u001b[34mtime: 1.793895959854126  count: 2000\u001b[0m\n",
      "\u001b[34mtime: 1.8530738353729248  count: 3000\u001b[0m\n",
      "\u001b[34mtime: 2.000584602355957  count: 4000\u001b[0m\n",
      "\u001b[34mCreating .rec file from /opt/ml/input/data/validation/val.lst in /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mtime: 0.014722347259521484  count: 0\u001b[0m\n",
      "\u001b[34mtime: 1.8063833713531494  count: 1000\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:18 INFO 140696405849920] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:18 WARNING 140696405849920] Training images are resized to image shape (3, 512, 512)\u001b[0m\n",
      "\u001b[34m[00:31:18] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[00:31:19] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, label padding width: 600\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:20 WARNING 140696405849920] Validation images are resized to image shape (3, 512, 512)\u001b[0m\n",
      "\u001b[34m[00:31:20] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[00:31:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, label padding width: 600\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:23 INFO 140696405849920] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:23 INFO 140696405849920] Using [gpu(0)] as training context.\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:23 INFO 140696405849920] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:23 INFO 140696405849920] Create Store: device\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:23 INFO 140696405849920] Using (gpu(0)) as training context.\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:24 INFO 140696405849920] Start training from pretrained model 1.\u001b[0m\n",
      "\u001b[34m[00:31:24] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[00:31:24] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:24 INFO 140696405849920] Loaded pretrained model parameters.\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:31:37 INFO 140696405849920] Creating a new state instance.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623630697.0650039, \"EndTime\": 1623630697.065072, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[00:31:37] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.135.0/AL2_x86_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:32:19 INFO 140696405849920] Epoch:    0, batches:    100, num_examples:   1600, 38.1 samples/sec, epoch time so far:  0:00:41.963906\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:32:54 INFO 140696405849920] Epoch:    0, batches:    200, num_examples:   3200, 41.2 samples/sec, epoch time so far:  0:01:17.734018\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:30 INFO 140696405849920] Epoch:    0, batches:    300, num_examples:   4800, 42.4 samples/sec, epoch time so far:  0:01:53.176372\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:33 INFO 140696405849920] #quality_metric: host=algo-1, epoch=0, batch=310 train cross_entropy <loss>=(2.7062921315851023)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:33 INFO 140696405849920] #quality_metric: host=algo-1, epoch=0, batch=310 train smooth_l1 <loss>=(0.9417550366800125)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:33 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:33 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:59 INFO 140696405849920] #quality_metric: host=algo-1, epoch=0, validation mAP <score>=(0.00017480117365520977)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:59 INFO 140696405849920] Updating the best model with validation-mAP=0.00017480117365520977\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:59 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:33:59 INFO 140696405849920] #progress_metric: host=algo-1, completed 3.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623630697.065363, \"EndTime\": 1623630839.877487, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:34:36 INFO 140696405849920] Epoch:    1, batches:    100, num_examples:   1600, 43.6 samples/sec, epoch time so far:  0:00:36.667119\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:35:12 INFO 140696405849920] Epoch:    1, batches:    200, num_examples:   3200, 44.0 samples/sec, epoch time so far:  0:01:12.732071\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:35:47 INFO 140696405849920] Epoch:    1, batches:    300, num_examples:   4800, 44.6 samples/sec, epoch time so far:  0:01:47.505547\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:35:50 INFO 140696405849920] #quality_metric: host=algo-1, epoch=1, batch=309 train cross_entropy <loss>=(1.5446960971496604)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:35:50 INFO 140696405849920] #quality_metric: host=algo-1, epoch=1, batch=309 train smooth_l1 <loss>=(0.8707930386562767)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:35:50 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:35:50 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:36:15 INFO 140696405849920] #quality_metric: host=algo-1, epoch=1, validation mAP <score>=(0.00022563490913249195)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:36:15 INFO 140696405849920] Updating the best model with validation-mAP=0.00022563490913249195\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:36:15 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:36:15 INFO 140696405849920] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623630839.8777843, \"EndTime\": 1623630975.3022268, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:36:52 INFO 140696405849920] Epoch:    2, batches:    100, num_examples:   1600, 42.7 samples/sec, epoch time so far:  0:00:37.514533\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:37:29 INFO 140696405849920] Epoch:    2, batches:    200, num_examples:   3200, 43.3 samples/sec, epoch time so far:  0:01:13.888072\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:04 INFO 140696405849920] Epoch:    2, batches:    300, num_examples:   4800, 44.0 samples/sec, epoch time so far:  0:01:49.100078\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:07 INFO 140696405849920] #quality_metric: host=algo-1, epoch=2, batch=310 train cross_entropy <loss>=(1.4836116358201359)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:07 INFO 140696405849920] #quality_metric: host=algo-1, epoch=2, batch=310 train smooth_l1 <loss>=(0.808146751079122)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:07 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:07 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:32 INFO 140696405849920] #quality_metric: host=algo-1, epoch=2, validation mAP <score>=(0.0006133066814601473)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:32 INFO 140696405849920] Updating the best model with validation-mAP=0.0006133066814601473\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:32 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:38:32 INFO 140696405849920] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623630975.3024745, \"EndTime\": 1623631112.8755603, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:39:09 INFO 140696405849920] Epoch:    3, batches:    100, num_examples:   1600, 43.2 samples/sec, epoch time so far:  0:00:37.050587\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:39:46 INFO 140696405849920] Epoch:    3, batches:    200, num_examples:   3200, 43.6 samples/sec, epoch time so far:  0:01:13.474888\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:21 INFO 140696405849920] Epoch:    3, batches:    300, num_examples:   4800, 44.2 samples/sec, epoch time so far:  0:01:48.555716\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:24 INFO 140696405849920] #quality_metric: host=algo-1, epoch=3, batch=309 train cross_entropy <loss>=(1.4680557823229086)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:24 INFO 140696405849920] #quality_metric: host=algo-1, epoch=3, batch=309 train smooth_l1 <loss>=(0.7635962686426421)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:24 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:24 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:47 INFO 140696405849920] #quality_metric: host=algo-1, epoch=3, validation mAP <score>=(0.0009768391662642577)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:47 INFO 140696405849920] Updating the best model with validation-mAP=0.0009768391662642577\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:48 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:40:48 INFO 140696405849920] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631112.8758428, \"EndTime\": 1623631248.131808, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:41:25 INFO 140696405849920] Epoch:    4, batches:    100, num_examples:   1600, 42.7 samples/sec, epoch time so far:  0:00:37.440254\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:42:01 INFO 140696405849920] Epoch:    4, batches:    200, num_examples:   3200, 43.5 samples/sec, epoch time so far:  0:01:13.598591\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:42:36 INFO 140696405849920] Epoch:    4, batches:    300, num_examples:   4800, 44.1 samples/sec, epoch time so far:  0:01:48.772438\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:42:39 INFO 140696405849920] #quality_metric: host=algo-1, epoch=4, batch=310 train cross_entropy <loss>=(1.4510632729231538)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:42:39 INFO 140696405849920] #quality_metric: host=algo-1, epoch=4, batch=310 train smooth_l1 <loss>=(0.7390415437385923)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:42:39 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:42:40 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:43:04 INFO 140696405849920] #quality_metric: host=algo-1, epoch=4, validation mAP <score>=(0.0012941562028927199)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:43:04 INFO 140696405849920] Updating the best model with validation-mAP=0.0012941562028927199\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:43:05 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:43:05 INFO 140696405849920] #progress_metric: host=algo-1, completed 16.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631248.1320944, \"EndTime\": 1623631385.1746063, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:43:41 INFO 140696405849920] Epoch:    5, batches:    100, num_examples:   1600, 44.0 samples/sec, epoch time so far:  0:00:36.371279\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:44:17 INFO 140696405849920] Epoch:    5, batches:    200, num_examples:   3200, 44.0 samples/sec, epoch time so far:  0:01:12.768195\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:44:52 INFO 140696405849920] Epoch:    5, batches:    300, num_examples:   4800, 44.8 samples/sec, epoch time so far:  0:01:47.133771\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:44:55 INFO 140696405849920] #quality_metric: host=algo-1, epoch=5, batch=309 train cross_entropy <loss>=(1.431689251327151)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:44:55 INFO 140696405849920] #quality_metric: host=algo-1, epoch=5, batch=309 train smooth_l1 <loss>=(0.723189270750344)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:44:55 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:44:55 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:45:19 INFO 140696405849920] #quality_metric: host=algo-1, epoch=5, validation mAP <score>=(0.001689556716508118)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:45:19 INFO 140696405849920] Updating the best model with validation-mAP=0.001689556716508118\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:45:19 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:45:19 INFO 140696405849920] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631385.17485, \"EndTime\": 1623631519.303593, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:45:56 INFO 140696405849920] Epoch:    6, batches:    100, num_examples:   1600, 43.1 samples/sec, epoch time so far:  0:00:37.085180\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:46:32 INFO 140696405849920] Epoch:    6, batches:    200, num_examples:   3200, 43.6 samples/sec, epoch time so far:  0:01:13.328442\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:07 INFO 140696405849920] Epoch:    6, batches:    300, num_examples:   4800, 44.2 samples/sec, epoch time so far:  0:01:48.591199\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:10 INFO 140696405849920] #quality_metric: host=algo-1, epoch=6, batch=310 train cross_entropy <loss>=(1.4201250472209543)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:10 INFO 140696405849920] #quality_metric: host=algo-1, epoch=6, batch=310 train smooth_l1 <loss>=(0.7048707562980127)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:10 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:11 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:36 INFO 140696405849920] #quality_metric: host=algo-1, epoch=6, validation mAP <score>=(0.0019784036601414607)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:36 INFO 140696405849920] Updating the best model with validation-mAP=0.0019784036601414607\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:36 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:47:36 INFO 140696405849920] #progress_metric: host=algo-1, completed 23.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631519.303824, \"EndTime\": 1623631656.762306, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:48:13 INFO 140696405849920] Epoch:    7, batches:    100, num_examples:   1600, 43.8 samples/sec, epoch time so far:  0:00:36.537202\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:48:49 INFO 140696405849920] Epoch:    7, batches:    200, num_examples:   3200, 44.1 samples/sec, epoch time so far:  0:01:12.644626\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:24 INFO 140696405849920] Epoch:    7, batches:    300, num_examples:   4800, 44.7 samples/sec, epoch time so far:  0:01:47.355859\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:26 INFO 140696405849920] #quality_metric: host=algo-1, epoch=7, batch=309 train cross_entropy <loss>=(1.4074172137440522)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:26 INFO 140696405849920] #quality_metric: host=algo-1, epoch=7, batch=309 train smooth_l1 <loss>=(0.6900221776385435)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:26 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:26 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:51 INFO 140696405849920] #quality_metric: host=algo-1, epoch=7, validation mAP <score>=(0.004544516525345749)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:51 INFO 140696405849920] Updating the best model with validation-mAP=0.004544516525345749\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:51 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:49:51 INFO 140696405849920] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631656.762616, \"EndTime\": 1623631791.5692334, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:50:29 INFO 140696405849920] Epoch:    8, batches:    100, num_examples:   1600, 42.0 samples/sec, epoch time so far:  0:00:38.084197\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:05 INFO 140696405849920] Epoch:    8, batches:    200, num_examples:   3200, 43.1 samples/sec, epoch time so far:  0:01:14.174332\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:41 INFO 140696405849920] Epoch:    8, batches:    300, num_examples:   4800, 43.8 samples/sec, epoch time so far:  0:01:49.530468\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:42 INFO 140696405849920] Update[2781]: Change learning rate to 1.00000e-04\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:44 INFO 140696405849920] #quality_metric: host=algo-1, epoch=8, batch=310 train cross_entropy <loss>=(1.4004395211653544)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:44 INFO 140696405849920] #quality_metric: host=algo-1, epoch=8, batch=310 train smooth_l1 <loss>=(0.6709614950078733)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:44 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:51:44 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:52:10 INFO 140696405849920] #quality_metric: host=algo-1, epoch=8, validation mAP <score>=(0.005349422873187487)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:52:10 INFO 140696405849920] Updating the best model with validation-mAP=0.005349422873187487\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:52:10 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:52:10 INFO 140696405849920] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631791.5694792, \"EndTime\": 1623631930.3354201, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:52:46 INFO 140696405849920] Epoch:    9, batches:    100, num_examples:   1600, 44.0 samples/sec, epoch time so far:  0:00:36.351679\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:53:22 INFO 140696405849920] Epoch:    9, batches:    200, num_examples:   3200, 44.1 samples/sec, epoch time so far:  0:01:12.572938\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:53:57 INFO 140696405849920] Epoch:    9, batches:    300, num_examples:   4800, 44.9 samples/sec, epoch time so far:  0:01:46.887835\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:53:59 INFO 140696405849920] #quality_metric: host=algo-1, epoch=9, batch=309 train cross_entropy <loss>=(1.389313590826025)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:53:59 INFO 140696405849920] #quality_metric: host=algo-1, epoch=9, batch=309 train smooth_l1 <loss>=(0.6635186661217397)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:53:59 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:54:00 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:54:24 INFO 140696405849920] #quality_metric: host=algo-1, epoch=9, validation mAP <score>=(0.0060700336874602735)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:54:24 INFO 140696405849920] Updating the best model with validation-mAP=0.0060700336874602735\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:54:25 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:54:25 INFO 140696405849920] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623631930.3358014, \"EndTime\": 1623632065.1556206, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:55:02 INFO 140696405849920] Epoch:    10, batches:    100, num_examples:   1600, 43.2 samples/sec, epoch time so far:  0:00:37.073564\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:55:38 INFO 140696405849920] Epoch:    10, batches:    200, num_examples:   3200, 43.9 samples/sec, epoch time so far:  0:01:12.965177\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:13 INFO 140696405849920] Epoch:    10, batches:    300, num_examples:   4800, 44.3 samples/sec, epoch time so far:  0:01:48.336281\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:16 INFO 140696405849920] #quality_metric: host=algo-1, epoch=10, batch=310 train cross_entropy <loss>=(1.3823697832038493)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:16 INFO 140696405849920] #quality_metric: host=algo-1, epoch=10, batch=310 train smooth_l1 <loss>=(0.6549865951616708)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:16 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:16 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:42 INFO 140696405849920] #quality_metric: host=algo-1, epoch=10, validation mAP <score>=(0.006523860364486473)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:42 INFO 140696405849920] Updating the best model with validation-mAP=0.006523860364486473\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:42 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:56:42 INFO 140696405849920] #progress_metric: host=algo-1, completed 36.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632065.1642568, \"EndTime\": 1623632202.2907367, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:57:19 INFO 140696405849920] Epoch:    11, batches:    100, num_examples:   1600, 43.5 samples/sec, epoch time so far:  0:00:36.772391\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:57:55 INFO 140696405849920] Epoch:    11, batches:    200, num_examples:   3200, 43.8 samples/sec, epoch time so far:  0:01:13.081724\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:30 INFO 140696405849920] Epoch:    11, batches:    300, num_examples:   4800, 44.5 samples/sec, epoch time so far:  0:01:47.936316\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:32 INFO 140696405849920] #quality_metric: host=algo-1, epoch=11, batch=309 train cross_entropy <loss>=(1.3907818914082115)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:32 INFO 140696405849920] #quality_metric: host=algo-1, epoch=11, batch=309 train smooth_l1 <loss>=(0.6563767788748891)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:32 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:33 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:57 INFO 140696405849920] #quality_metric: host=algo-1, epoch=11, validation mAP <score>=(0.006471865503437246)\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:58:57 INFO 140696405849920] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632202.2909567, \"EndTime\": 1623632337.5596437, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 00:59:35 INFO 140696405849920] Epoch:    12, batches:    100, num_examples:   1600, 42.3 samples/sec, epoch time so far:  0:00:37.799693\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:00:11 INFO 140696405849920] Epoch:    12, batches:    200, num_examples:   3200, 43.0 samples/sec, epoch time so far:  0:01:14.380988\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:00:46 INFO 140696405849920] Epoch:    12, batches:    300, num_examples:   4800, 43.9 samples/sec, epoch time so far:  0:01:49.416764\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:00:49 INFO 140696405849920] #quality_metric: host=algo-1, epoch=12, batch=310 train cross_entropy <loss>=(1.3854653070115177)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:00:49 INFO 140696405849920] #quality_metric: host=algo-1, epoch=12, batch=310 train smooth_l1 <loss>=(0.6580977595800014)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:00:49 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:00:50 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:01:16 INFO 140696405849920] #quality_metric: host=algo-1, epoch=12, validation mAP <score>=(0.0066544250970077806)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:01:16 INFO 140696405849920] Updating the best model with validation-mAP=0.0066544250970077806\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:01:16 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:01:16 INFO 140696405849920] #progress_metric: host=algo-1, completed 43.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632337.5598493, \"EndTime\": 1623632476.5151918, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:01:52 INFO 140696405849920] Epoch:    13, batches:    100, num_examples:   1600, 44.2 samples/sec, epoch time so far:  0:00:36.225997\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:02:29 INFO 140696405849920] Epoch:    13, batches:    200, num_examples:   3200, 44.1 samples/sec, epoch time so far:  0:01:12.612661\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:03 INFO 140696405849920] Epoch:    13, batches:    300, num_examples:   4800, 44.7 samples/sec, epoch time so far:  0:01:47.395298\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:06 INFO 140696405849920] #quality_metric: host=algo-1, epoch=13, batch=309 train cross_entropy <loss>=(1.3845709227689382)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:06 INFO 140696405849920] #quality_metric: host=algo-1, epoch=13, batch=309 train smooth_l1 <loss>=(0.6463023510980146)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:06 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:06 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:31 INFO 140696405849920] #quality_metric: host=algo-1, epoch=13, validation mAP <score>=(0.007356797945169052)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:31 INFO 140696405849920] Updating the best model with validation-mAP=0.007356797945169052\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:31 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:03:31 INFO 140696405849920] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632476.515433, \"EndTime\": 1623632611.318756, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:04:09 INFO 140696405849920] Epoch:    14, batches:    100, num_examples:   1600, 41.9 samples/sec, epoch time so far:  0:00:38.166911\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:04:45 INFO 140696405849920] Epoch:    14, batches:    200, num_examples:   3200, 43.3 samples/sec, epoch time so far:  0:01:13.978380\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:20 INFO 140696405849920] Epoch:    14, batches:    300, num_examples:   4800, 43.9 samples/sec, epoch time so far:  0:01:49.303415\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:23 INFO 140696405849920] #quality_metric: host=algo-1, epoch=14, batch=310 train cross_entropy <loss>=(1.3821547646900194)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:23 INFO 140696405849920] #quality_metric: host=algo-1, epoch=14, batch=310 train smooth_l1 <loss>=(0.6536861827699383)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:23 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:23 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:49 INFO 140696405849920] #quality_metric: host=algo-1, epoch=14, validation mAP <score>=(0.007069172220990003)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:05:49 INFO 140696405849920] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632611.319292, \"EndTime\": 1623632749.7525382, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:06:26 INFO 140696405849920] Epoch:    15, batches:    100, num_examples:   1600, 44.0 samples/sec, epoch time so far:  0:00:36.358562\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:07:02 INFO 140696405849920] Epoch:    15, batches:    200, num_examples:   3200, 44.2 samples/sec, epoch time so far:  0:01:12.456802\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:07:36 INFO 140696405849920] Epoch:    15, batches:    300, num_examples:   4800, 44.9 samples/sec, epoch time so far:  0:01:46.900060\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:07:39 INFO 140696405849920] #quality_metric: host=algo-1, epoch=15, batch=309 train cross_entropy <loss>=(1.3873795976824335)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:07:39 INFO 140696405849920] #quality_metric: host=algo-1, epoch=15, batch=309 train smooth_l1 <loss>=(0.6462268363361129)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:07:39 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:07:39 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:08:04 INFO 140696405849920] #quality_metric: host=algo-1, epoch=15, validation mAP <score>=(0.007940939055203803)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:08:04 INFO 140696405849920] Updating the best model with validation-mAP=0.007940939055203803\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:08:04 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:08:04 INFO 140696405849920] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632749.7527518, \"EndTime\": 1623632884.255585, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:08:42 INFO 140696405849920] Epoch:    16, batches:    100, num_examples:   1600, 42.1 samples/sec, epoch time so far:  0:00:38.022967\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:09:18 INFO 140696405849920] Epoch:    16, batches:    200, num_examples:   3200, 43.0 samples/sec, epoch time so far:  0:01:14.438791\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:09:53 INFO 140696405849920] Epoch:    16, batches:    300, num_examples:   4800, 43.8 samples/sec, epoch time so far:  0:01:49.574088\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:09:56 INFO 140696405849920] #quality_metric: host=algo-1, epoch=16, batch=310 train cross_entropy <loss>=(1.3800566584006437)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:09:56 INFO 140696405849920] #quality_metric: host=algo-1, epoch=16, batch=310 train smooth_l1 <loss>=(0.6505798945511015)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:09:56 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:09:57 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:10:23 INFO 140696405849920] #quality_metric: host=algo-1, epoch=16, validation mAP <score>=(0.00814890259454594)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:10:23 INFO 140696405849920] Updating the best model with validation-mAP=0.00814890259454594\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:10:24 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:10:24 INFO 140696405849920] #progress_metric: host=algo-1, completed 56.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623632884.2558568, \"EndTime\": 1623633024.0736017, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:10:59 INFO 140696405849920] Epoch:    17, batches:    100, num_examples:   1600, 44.5 samples/sec, epoch time so far:  0:00:35.919323\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:11:36 INFO 140696405849920] Epoch:    17, batches:    200, num_examples:   3200, 44.1 samples/sec, epoch time so far:  0:01:12.559601\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:11 INFO 140696405849920] Epoch:    17, batches:    300, num_examples:   4800, 44.8 samples/sec, epoch time so far:  0:01:47.185546\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:13 INFO 140696405849920] #quality_metric: host=algo-1, epoch=17, batch=309 train cross_entropy <loss>=(1.3812747307138353)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:13 INFO 140696405849920] #quality_metric: host=algo-1, epoch=17, batch=309 train smooth_l1 <loss>=(0.64819319624797)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:13 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:14 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:38 INFO 140696405849920] #quality_metric: host=algo-1, epoch=17, validation mAP <score>=(0.008364788945086252)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:38 INFO 140696405849920] Updating the best model with validation-mAP=0.008364788945086252\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:38 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:12:38 INFO 140696405849920] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633024.0738404, \"EndTime\": 1623633158.7017848, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:13:16 INFO 140696405849920] Epoch:    18, batches:    100, num_examples:   1600, 42.2 samples/sec, epoch time so far:  0:00:37.912016\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:13:52 INFO 140696405849920] Epoch:    18, batches:    200, num_examples:   3200, 43.3 samples/sec, epoch time so far:  0:01:13.847095\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:27 INFO 140696405849920] Epoch:    18, batches:    300, num_examples:   4800, 44.1 samples/sec, epoch time so far:  0:01:48.959571\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:30 INFO 140696405849920] #quality_metric: host=algo-1, epoch=18, batch=310 train cross_entropy <loss>=(1.3806192127518182)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:30 INFO 140696405849920] #quality_metric: host=algo-1, epoch=18, batch=310 train smooth_l1 <loss>=(0.6431713234032308)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:30 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:30 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:56 INFO 140696405849920] #quality_metric: host=algo-1, epoch=18, validation mAP <score>=(0.0082617079031565)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:14:56 INFO 140696405849920] #progress_metric: host=algo-1, completed 63.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633158.7020316, \"EndTime\": 1623633296.618975, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:15:33 INFO 140696405849920] Epoch:    19, batches:    100, num_examples:   1600, 43.6 samples/sec, epoch time so far:  0:00:36.682439\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:16:09 INFO 140696405849920] Epoch:    19, batches:    200, num_examples:   3200, 44.0 samples/sec, epoch time so far:  0:01:12.736773\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:16:43 INFO 140696405849920] Epoch:    19, batches:    300, num_examples:   4800, 44.8 samples/sec, epoch time so far:  0:01:47.220636\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:16:46 INFO 140696405849920] #quality_metric: host=algo-1, epoch=19, batch=309 train cross_entropy <loss>=(1.3781168441656446)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:16:46 INFO 140696405849920] #quality_metric: host=algo-1, epoch=19, batch=309 train smooth_l1 <loss>=(0.6411350094363507)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:16:46 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:16:46 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:17:11 INFO 140696405849920] #quality_metric: host=algo-1, epoch=19, validation mAP <score>=(0.008473713332837496)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:17:11 INFO 140696405849920] Updating the best model with validation-mAP=0.008473713332837496\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:17:11 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:17:12 INFO 140696405849920] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633296.619284, \"EndTime\": 1623633432.035716, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:17:49 INFO 140696405849920] Epoch:    20, batches:    100, num_examples:   1600, 42.5 samples/sec, epoch time so far:  0:00:37.658651\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:18:25 INFO 140696405849920] Epoch:    20, batches:    200, num_examples:   3200, 43.3 samples/sec, epoch time so far:  0:01:13.887165\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:01 INFO 140696405849920] Epoch:    20, batches:    300, num_examples:   4800, 44.0 samples/sec, epoch time so far:  0:01:48.967740\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:04 INFO 140696405849920] #quality_metric: host=algo-1, epoch=20, batch=310 train cross_entropy <loss>=(1.376711702947408)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:04 INFO 140696405849920] #quality_metric: host=algo-1, epoch=20, batch=310 train smooth_l1 <loss>=(0.6525414415051014)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:04 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:04 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:30 INFO 140696405849920] #quality_metric: host=algo-1, epoch=20, validation mAP <score>=(0.009107175192356482)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:30 INFO 140696405849920] Updating the best model with validation-mAP=0.009107175192356482\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:30 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:19:30 INFO 140696405849920] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633432.0359833, \"EndTime\": 1623633570.3673198, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:20:06 INFO 140696405849920] Epoch:    21, batches:    100, num_examples:   1600, 43.7 samples/sec, epoch time so far:  0:00:36.585245\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:20:43 INFO 140696405849920] Epoch:    21, batches:    200, num_examples:   3200, 44.0 samples/sec, epoch time so far:  0:01:12.650866\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:17 INFO 140696405849920] Epoch:    21, batches:    300, num_examples:   4800, 44.9 samples/sec, epoch time so far:  0:01:46.988476\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:20 INFO 140696405849920] #quality_metric: host=algo-1, epoch=21, batch=309 train cross_entropy <loss>=(1.3779604866729576)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:20 INFO 140696405849920] #quality_metric: host=algo-1, epoch=21, batch=309 train smooth_l1 <loss>=(0.6382785224054205)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:20 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:20 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:45 INFO 140696405849920] #quality_metric: host=algo-1, epoch=21, validation mAP <score>=(0.0089509129823191)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:21:45 INFO 140696405849920] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633570.3678408, \"EndTime\": 1623633705.0350013, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:22:23 INFO 140696405849920] Epoch:    22, batches:    100, num_examples:   1600, 42.0 samples/sec, epoch time so far:  0:00:38.139139\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:22:58 INFO 140696405849920] Epoch:    22, batches:    200, num_examples:   3200, 43.4 samples/sec, epoch time so far:  0:01:13.762668\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:23:34 INFO 140696405849920] Epoch:    22, batches:    300, num_examples:   4800, 43.9 samples/sec, epoch time so far:  0:01:49.385114\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:23:37 INFO 140696405849920] #quality_metric: host=algo-1, epoch=22, batch=310 train cross_entropy <loss>=(1.3709848240822018)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:23:37 INFO 140696405849920] #quality_metric: host=algo-1, epoch=22, batch=310 train smooth_l1 <loss>=(0.6423817302649019)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:23:37 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:23:37 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:24:03 INFO 140696405849920] #quality_metric: host=algo-1, epoch=22, validation mAP <score>=(0.009045800458371792)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:24:03 INFO 140696405849920] #progress_metric: host=algo-1, completed 76.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633705.0353713, \"EndTime\": 1623633843.433956, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:24:39 INFO 140696405849920] Epoch:    23, batches:    100, num_examples:   1600, 43.9 samples/sec, epoch time so far:  0:00:36.426102\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:25:15 INFO 140696405849920] Epoch:    23, batches:    200, num_examples:   3200, 44.2 samples/sec, epoch time so far:  0:01:12.467134\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:25:50 INFO 140696405849920] Epoch:    23, batches:    300, num_examples:   4800, 44.7 samples/sec, epoch time so far:  0:01:47.380601\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:25:53 INFO 140696405849920] #quality_metric: host=algo-1, epoch=23, batch=309 train cross_entropy <loss>=(1.3676388198195417)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:25:53 INFO 140696405849920] #quality_metric: host=algo-1, epoch=23, batch=309 train smooth_l1 <loss>=(0.6325774300154587)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:25:53 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:25:53 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:26:18 INFO 140696405849920] #quality_metric: host=algo-1, epoch=23, validation mAP <score>=(0.009670159510064159)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:26:18 INFO 140696405849920] Updating the best model with validation-mAP=0.009670159510064159\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:26:18 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:26:18 INFO 140696405849920] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633843.4341855, \"EndTime\": 1623633978.8596005, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:26:56 INFO 140696405849920] Epoch:    24, batches:    100, num_examples:   1600, 42.8 samples/sec, epoch time so far:  0:00:37.391109\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:27:32 INFO 140696405849920] Epoch:    24, batches:    200, num_examples:   3200, 43.5 samples/sec, epoch time so far:  0:01:13.550104\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:07 INFO 140696405849920] Epoch:    24, batches:    300, num_examples:   4800, 44.0 samples/sec, epoch time so far:  0:01:48.975715\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:10 INFO 140696405849920] #quality_metric: host=algo-1, epoch=24, batch=310 train cross_entropy <loss>=(1.373225787150958)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:10 INFO 140696405849920] #quality_metric: host=algo-1, epoch=24, batch=310 train smooth_l1 <loss>=(0.6388263216266146)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:10 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:10 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:36 INFO 140696405849920] #quality_metric: host=algo-1, epoch=24, validation mAP <score>=(0.010767970729988885)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:36 INFO 140696405849920] Updating the best model with validation-mAP=0.010767970729988885\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:37 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:28:37 INFO 140696405849920] #progress_metric: host=algo-1, completed 83.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623633978.8598304, \"EndTime\": 1623634117.0357294, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:29:13 INFO 140696405849920] Epoch:    25, batches:    100, num_examples:   1600, 43.5 samples/sec, epoch time so far:  0:00:36.796955\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:29:49 INFO 140696405849920] Epoch:    25, batches:    200, num_examples:   3200, 44.0 samples/sec, epoch time so far:  0:01:12.712108\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:24 INFO 140696405849920] Epoch:    25, batches:    300, num_examples:   4800, 44.5 samples/sec, epoch time so far:  0:01:47.872588\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:27 INFO 140696405849920] #quality_metric: host=algo-1, epoch=25, batch=309 train cross_entropy <loss>=(1.3660607627012982)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:27 INFO 140696405849920] #quality_metric: host=algo-1, epoch=25, batch=309 train smooth_l1 <loss>=(0.6334833327784051)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:27 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:27 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:52 INFO 140696405849920] #quality_metric: host=algo-1, epoch=25, validation mAP <score>=(0.010260101994874716)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:30:52 INFO 140696405849920] #progress_metric: host=algo-1, completed 86.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623634117.045067, \"EndTime\": 1623634252.4069037, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:31:30 INFO 140696405849920] Epoch:    26, batches:    100, num_examples:   1600, 42.4 samples/sec, epoch time so far:  0:00:37.694533\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:32:06 INFO 140696405849920] Epoch:    26, batches:    200, num_examples:   3200, 43.4 samples/sec, epoch time so far:  0:01:13.737836\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:32:41 INFO 140696405849920] Epoch:    26, batches:    300, num_examples:   4800, 44.1 samples/sec, epoch time so far:  0:01:48.926766\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:32:44 INFO 140696405849920] #quality_metric: host=algo-1, epoch=26, batch=310 train cross_entropy <loss>=(1.3759696409280164)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:32:44 INFO 140696405849920] #quality_metric: host=algo-1, epoch=26, batch=310 train smooth_l1 <loss>=(0.6404666163735261)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:32:44 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:32:44 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:33:10 INFO 140696405849920] #quality_metric: host=algo-1, epoch=26, validation mAP <score>=(0.011923922577097748)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:33:10 INFO 140696405849920] Updating the best model with validation-mAP=0.011923922577097748\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:33:11 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:33:11 INFO 140696405849920] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623634252.4071112, \"EndTime\": 1623634391.1570125, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:33:47 INFO 140696405849920] Epoch:    27, batches:    100, num_examples:   1600, 44.2 samples/sec, epoch time so far:  0:00:36.177355\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:34:23 INFO 140696405849920] Epoch:    27, batches:    200, num_examples:   3200, 44.0 samples/sec, epoch time so far:  0:01:12.713297\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:34:58 INFO 140696405849920] Epoch:    27, batches:    300, num_examples:   4800, 44.8 samples/sec, epoch time so far:  0:01:47.242412\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:01 INFO 140696405849920] #quality_metric: host=algo-1, epoch=27, batch=309 train cross_entropy <loss>=(1.3691186307922956)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:01 INFO 140696405849920] #quality_metric: host=algo-1, epoch=27, batch=309 train smooth_l1 <loss>=(0.6278694280458706)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:01 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:01 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:26 INFO 140696405849920] #quality_metric: host=algo-1, epoch=27, validation mAP <score>=(0.012219712121462657)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:26 INFO 140696405849920] Updating the best model with validation-mAP=0.012219712121462657\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:26 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:35:26 INFO 140696405849920] #progress_metric: host=algo-1, completed 93.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623634391.1572447, \"EndTime\": 1623634526.2076924, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:36:03 INFO 140696405849920] Epoch:    28, batches:    100, num_examples:   1600, 42.4 samples/sec, epoch time so far:  0:00:37.723939\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:36:39 INFO 140696405849920] Epoch:    28, batches:    200, num_examples:   3200, 43.5 samples/sec, epoch time so far:  0:01:13.534014\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:15 INFO 140696405849920] Epoch:    28, batches:    300, num_examples:   4800, 44.0 samples/sec, epoch time so far:  0:01:48.993111\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:18 INFO 140696405849920] #quality_metric: host=algo-1, epoch=28, batch=310 train cross_entropy <loss>=(1.3705302797837167)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:18 INFO 140696405849920] #quality_metric: host=algo-1, epoch=28, batch=310 train smooth_l1 <loss>=(0.6360003791055242)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:18 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:18 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:43 INFO 140696405849920] #quality_metric: host=algo-1, epoch=28, validation mAP <score>=(0.012418062484067616)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:43 INFO 140696405849920] Updating the best model with validation-mAP=0.012418062484067616\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:43 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:37:43 INFO 140696405849920] #progress_metric: host=algo-1, completed 96.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623634526.2081115, \"EndTime\": 1623634663.9532943, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:38:20 INFO 140696405849920] Epoch:    29, batches:    100, num_examples:   1600, 43.7 samples/sec, epoch time so far:  0:00:36.591622\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:38:56 INFO 140696405849920] Epoch:    29, batches:    200, num_examples:   3200, 44.2 samples/sec, epoch time so far:  0:01:12.455505\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:31 INFO 140696405849920] Epoch:    29, batches:    300, num_examples:   4800, 44.7 samples/sec, epoch time so far:  0:01:47.264249\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:33 INFO 140696405849920] #quality_metric: host=algo-1, epoch=29, batch=309 train cross_entropy <loss>=(1.3661768198868114)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:33 INFO 140696405849920] #quality_metric: host=algo-1, epoch=29, batch=309 train smooth_l1 <loss>=(0.6290552753025964)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:33 INFO 140696405849920] Round of batches complete\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:34 INFO 140696405849920] Updated the metrics\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:58 INFO 140696405849920] #quality_metric: host=algo-1, epoch=29, validation mAP <score>=(0.01310449894412775)\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:58 INFO 140696405849920] Updating the best model with validation-mAP=0.01310449894412775\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:59 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:59 INFO 140696405849920] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623634663.9536514, \"EndTime\": 1623634799.028464, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:59 WARNING 140696405849920] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:59 INFO 140696405849920] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/14/2021 01:39:59 INFO 140696405849920] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623630656.63768, \"EndTime\": 1623634800.3325565, \"Dimensions\": {\"Algorithm\": \"AWS/Object Detection\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"setuptime\": {\"sum\": 8.66079330444336, \"count\": 1, \"min\": 8.66079330444336, \"max\": 8.66079330444336}, \"totaltime\": {\"sum\": 4143819.3883895874, \"count\": 1, \"min\": 4143819.3883895874, \"max\": 4143819.3883895874}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-06-14 01:40:22 Uploading - Uploading generated training model\n",
      "2021-06-14 01:40:42 Completed - Training job completed\n",
      "ProfilerReport-1623630311: IssuesFound\n",
      "Training seconds: 4354\n",
      "Billable seconds: 4354\n"
     ]
    }
   ],
   "source": [
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-integration",
   "metadata": {
    "papermill": {
     "duration": 0.071551,
     "end_time": "2021-06-14T01:41:11.769923",
     "exception": false,
     "start_time": "2021-06-14T01:41:11.698372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hosting\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don't have to host on the same insantance (or type of instance) that we used to train. Training is a prolonged and compute heavy job that require a different of compute and memory requirements that hosting typically do not. We can choose any type of instance we want to host the model. In our case we chose the `ml.p3.2xlarge` instance to train, but we choose to host the model on the less expensive cpu instance, `ml.m4.xlarge`. The endpoint deployment can be accomplished as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "transparent-story",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T01:41:11.919168Z",
     "iopub.status.busy": "2021-06-14T01:41:11.918553Z",
     "iopub.status.idle": "2021-06-14T01:48:44.122522Z",
     "shell.execute_reply": "2021-06-14T01:48:44.122973Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 452.281605,
     "end_time": "2021-06-14T01:48:44.123127",
     "exception": false,
     "start_time": "2021-06-14T01:41:11.841522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "object_detector = od_model.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-amount",
   "metadata": {
    "papermill": {
     "duration": 0.075306,
     "end_time": "2021-06-14T01:48:44.274784",
     "exception": false,
     "start_time": "2021-06-14T01:48:44.199478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference\n",
    "Now that the trained model is deployed at an endpoint that is up-and-running, we can use this endpoint for inference. To do this, let us download an image from [PEXELS](https://www.pexels.com/) which the algorithm has so-far not seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "received-humidity",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T01:48:44.431574Z",
     "iopub.status.busy": "2021-06-14T01:48:44.430998Z",
     "iopub.status.idle": "2021-06-14T01:48:44.662136Z",
     "shell.execute_reply": "2021-06-14T01:48:44.661640Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.311921,
     "end_time": "2021-06-14T01:48:44.662262",
     "exception": false,
     "start_time": "2021-06-14T01:48:44.350341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-14 01:48:44--  https://images.pexels.com/photos/980382/pexels-photo-980382.jpeg\n",
      "Resolving images.pexels.com (images.pexels.com)... 104.17.209.102, 104.17.208.102, 2606:4700::6811:d166, ...\n",
      "Connecting to images.pexels.com (images.pexels.com)|104.17.209.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 503 Service Temporarily Unavailable\n",
      "2021-06-14 01:48:44 ERROR 503: Service Temporarily Unavailable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O test.jpg https://images.pexels.com/photos/980382/pexels-photo-980382.jpeg\n",
    "file_name = \"test.jpg\"\n",
    "\n",
    "with open(file_name, \"rb\") as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "    ne = open(\"n.txt\", \"wb\")\n",
    "    ne.write(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-surname",
   "metadata": {
    "papermill": {
     "duration": 0.076565,
     "end_time": "2021-06-14T01:48:44.815132",
     "exception": false,
     "start_time": "2021-06-14T01:48:44.738567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us use our endpoint to try to detect objects within this image. Since the image is `jpeg`, we use the appropriate `content_type` to run the prediction job. The endpoint returns a JSON file that we can simply load and peek into."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-addition",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "competitive-nevada",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-14T01:48:44.973602Z",
     "iopub.status.busy": "2021-06-14T01:48:44.972114Z",
     "iopub.status.idle": "2021-06-14T01:48:45.076039Z",
     "shell.execute_reply": "2021-06-14T01:48:45.075125Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.184928,
     "end_time": "2021-06-14T01:48:45.076288",
     "exception": true,
     "start_time": "2021-06-14T01:48:44.891360",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c373d0a66cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image/jpeg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "object_detector.content_type = \"image/jpeg\"\n",
    "results = object_detector.predict(b)\n",
    "detections = json.loads(results)\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-conference",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The results are in a format that is similar to the input .lst file (See [RecordIO Notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_recordio_format.ipynb) for more details on the .lst file definition. )with an addition of a confidence score for each detected object. The format of the output can be represented as `[class_index, confidence_score, xmin, ymin, xmax, ymax]`. Typically, we don't consider low-confidence predictions.\n",
    "\n",
    "We have provided additional script to easily visualize the detection outputs. You can visulize the high-confidence preditions with bounding box by filtering out low-confidence detections using the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-charles",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "    \"\"\"\n",
    "    visualize detections in one image\n",
    "    Parameters:\n",
    "    ----------\n",
    "    img : numpy.array\n",
    "        image, in bgr format\n",
    "    dets : numpy.array\n",
    "        ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "        each row is one object\n",
    "    classes : tuple or list of str\n",
    "        class names\n",
    "    thresh : float\n",
    "        score threshold\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "\n",
    "    img = mpimg.imread(img_file)\n",
    "    plt.imshow(img)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    colors = dict()\n",
    "    for det in dets:\n",
    "        (klass, score, x0, y0, x1, y1) = det\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        cls_id = int(klass)\n",
    "        if cls_id not in colors:\n",
    "            colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "        xmin = int(x0 * width)\n",
    "        ymin = int(y0 * height)\n",
    "        xmax = int(x1 * width)\n",
    "        ymax = int(y1 * height)\n",
    "        rect = plt.Rectangle(\n",
    "            (xmin, ymin),\n",
    "            xmax - xmin,\n",
    "            ymax - ymin,\n",
    "            fill=False,\n",
    "            edgecolor=colors[cls_id],\n",
    "            linewidth=3.5,\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        class_name = str(cls_id)\n",
    "        if classes and len(classes) > cls_id:\n",
    "            class_name = classes[cls_id]\n",
    "        plt.gca().text(\n",
    "            xmin,\n",
    "            ymin - 2,\n",
    "            \"{:s} {:.3f}\".format(class_name, score),\n",
    "            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "            fontsize=12,\n",
    "            color=\"white\",\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-religious",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "For the sake of this notebook, we used a small portion of the COCO dataset for training and trained the model with only a few (30) epochs. This implies that the results might not be optimal. To achieve better detection results, you can try to use the more data from COCO dataset and train the model for more epochs. Tuning the hyperparameters, such as `mini_batch_size`, `learning_rate`, and `optimizer`, also helps to get a better detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-pulse",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "object_categories = [\n",
    "    \"person\",\n",
    "    \"bicycle\",\n",
    "    \"car\",\n",
    "    \"motorbike\",\n",
    "    \"aeroplane\",\n",
    "    \"bus\",\n",
    "    \"train\",\n",
    "    \"truck\",\n",
    "    \"boat\",\n",
    "    \"traffic light\",\n",
    "    \"fire hydrant\",\n",
    "    \"stop sign\",\n",
    "    \"parking meter\",\n",
    "    \"bench\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"sheep\",\n",
    "    \"cow\",\n",
    "    \"elephant\",\n",
    "    \"bear\",\n",
    "    \"zebra\",\n",
    "    \"giraffe\",\n",
    "    \"backpack\",\n",
    "    \"umbrella\",\n",
    "    \"handbag\",\n",
    "    \"tie\",\n",
    "    \"suitcase\",\n",
    "    \"frisbee\",\n",
    "    \"skis\",\n",
    "    \"snowboard\",\n",
    "    \"sports ball\",\n",
    "    \"kite\",\n",
    "    \"baseball bat\",\n",
    "    \"baseball glove\",\n",
    "    \"skateboard\",\n",
    "    \"surfboard\",\n",
    "    \"tennis racket\",\n",
    "    \"bottle\",\n",
    "    \"wine glass\",\n",
    "    \"cup\",\n",
    "    \"fork\",\n",
    "    \"knife\",\n",
    "    \"spoon\",\n",
    "    \"bowl\",\n",
    "    \"banana\",\n",
    "    \"apple\",\n",
    "    \"sandwich\",\n",
    "    \"orange\",\n",
    "    \"broccoli\",\n",
    "    \"carrot\",\n",
    "    \"hot dog\",\n",
    "    \"pizza\",\n",
    "    \"donut\",\n",
    "    \"cake\",\n",
    "    \"chair\",\n",
    "    \"sofa\",\n",
    "    \"pottedplant\",\n",
    "    \"bed\",\n",
    "    \"diningtable\",\n",
    "    \"toilet\",\n",
    "    \"tvmonitor\",\n",
    "    \"laptop\",\n",
    "    \"mouse\",\n",
    "    \"remote\",\n",
    "    \"keyboard\",\n",
    "    \"cell phone\",\n",
    "    \"microwave\",\n",
    "    \"oven\",\n",
    "    \"toaster\",\n",
    "    \"sink\",\n",
    "    \"refrigerator\",\n",
    "    \"book\",\n",
    "    \"clock\",\n",
    "    \"vase\",\n",
    "    \"scissors\",\n",
    "    \"teddy bear\",\n",
    "    \"hair drier\",\n",
    "    \"toothbrush\",\n",
    "]\n",
    "# Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20.\n",
    "threshold = 0.20\n",
    "\n",
    "# Visualize the detections.\n",
    "visualize_detection(file_name, detections[\"prediction\"], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-intellectual",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Delete the Endpoint\n",
    "Having an endpoint running will incur some costs. Therefore as a clean-up job, we should delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-therapist",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(object_detector.endpoint)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "papermill": {
   "default_parameters": {},
   "duration": 5781.184233,
   "end_time": "2021-06-14T01:48:45.660495",
   "environment_variables": {},
   "exception": true,
   "input_path": "object_detection_image_json_format.ipynb",
   "output_path": "/opt/ml/processing/output/object_detection_image_json_format-2021-06-14-00-08-32.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-14T00:12:24.476262",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
